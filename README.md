
# ğŸ“š UDST Academic Assistant

A **Retrieval-Augmented Generation (RAG)** chatbot that answers student questions 
using the University of Doha for Science and Technology (UDST) [Academic Catalog](https://www.udst.edu.qa/sites/default/files/2023-01/AcademicCatalog2022-2023.pdf). 

---
## ğŸ’¡ How It Works
```
PDF Catalog â†’ Extract Pages â†’ Chunk â†’ Embed â†’ Semantic Search â†’ LLM Answer
```
1. **Ingestion** â€” Downloads the catalog PDF and extracts text page by page
2. **Chunking** â€” Cleans and splits pages into semantically coherent chunks
3. **Embedding** â€” Converts chunks into vectors using BGE and saves to disk
4. **Retrieval** â€” Finds the most relevant chunks for a user query via cosine similarity
5. **Generation** â€” Sends retrieved chunks + query to LLaMA to generate a cited answer
   
---
## ğŸ¤– Models

| Role | Model |
|---|---|
| Embedding | `BAAI/bge-small-en-v1.5` |
| Language Model | `meta-llama/Llama-3.1-8B-Instruct` |

---

## ğŸ› ï¸ Tech Stack

- **Python** 3.10
- **Streamlit** â€” conversational web UI
- **FastAPI** â€” REST API endpoint
- **LangChain** â€” recursive text splitting
- **sentence-transformers** â€” BGE embeddings
- **HuggingFace** InferenceClient â€” LLaMA inference
- **pypdf** â€” PDF extraction

  
---
## ğŸ“ Project Structure
```
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingestion.py      # Download the catalog PDF and extract page-level text
â”‚   â”œâ”€â”€ chunking.py       # Clean and split pages into semantically coherent chunks
â”‚   â”œâ”€â”€ embedding.py      # Embed chunks into vectors and save to disk
â”‚   â”œâ”€â”€ retrieval.py      # Load embeddings and perform semantic search
â”‚   â””â”€â”€ generation.py     # Build prompt and call the LLM to generate answers
â”œâ”€â”€ main.py               # CLI pipeline: ingestion â†’ chunking â†’ embedding â†’ retrieval â†’ generation
â”œâ”€â”€ app.py                # Streamlit  Chat UI
â”œâ”€â”€ api.py             # FastAPI REST endpoint
â””â”€â”€ requirements.txt
```

## ğŸš€ Quick Start

```bash
# Install dependencies
pip install -r requirements.txt

# Create a `.env` file in the repo root and add your Hugging Face token:
# HF_TOKEN=your_hf_token_here

# Run the pipeline** (first time only â€” downloads PDF, chunks, embeds)
# python main.py

# Run the web UI
streamlit run app.py
```
---
## ğŸ’¬ Example Questions

- What are the admission requirements?
- What is the maximum number of allowed absences?
- What are the graduation requirements for a bachelor's degree?
- What scholarships are available for students?

---
**LLM RAG Project | 2025**
